{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl8STit5_oaN"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPFg45Xs_qso"
      },
      "outputs": [],
      "source": [
        "data = json.load(open(\"train_data.json\" ,  'r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_i-q4mJPQYC",
        "outputId": "189f1576-6ed0-4662-c087-eb31a6b49c0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
              " {'entities': [[1749, 1755, 'Companies worked at'],\n",
              "   [1696, 1702, 'Companies worked at'],\n",
              "   [1417, 1423, 'Companies worked at'],\n",
              "   [1356, 1793, 'Skills'],\n",
              "   [1209, 1215, 'Companies worked at'],\n",
              "   [1136, 1247, 'Skills'],\n",
              "   [928, 932, 'Graduation Year'],\n",
              "   [858, 889, 'College Name'],\n",
              "   [821, 856, 'Degree'],\n",
              "   [787, 791, 'Graduation Year'],\n",
              "   [744, 750, 'Companies worked at'],\n",
              "   [722, 742, 'Designation'],\n",
              "   [658, 664, 'Companies worked at'],\n",
              "   [640, 656, 'Designation'],\n",
              "   [574, 580, 'Companies worked at'],\n",
              "   [555, 572, 'Designation'],\n",
              "   [470, 493, 'Companies worked at'],\n",
              "   [444, 468, 'Designation'],\n",
              "   [308, 314, 'Companies worked at'],\n",
              "   [234, 240, 'Companies worked at'],\n",
              "   [175, 198, 'Companies worked at'],\n",
              "   [93, 136, 'Email Address'],\n",
              "   [39, 48, 'Location'],\n",
              "   [13, 37, 'Designation'],\n",
              "   [0, 12, 'Name']]}]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpDug-gKKhKX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train  , test = train_test_split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVjfmyX9AJqf",
        "outputId": "c507f20c-d0d6-4f3d-d71d-fb72efea5e00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 16/150 [00:00<00:02, 65.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 36/150 [00:00<00:01, 68.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 52/150 [00:00<00:01, 68.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▊     | 73/150 [00:00<00:00, 82.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 91/150 [00:01<00:00, 83.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 100/150 [00:01<00:00, 78.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 118/150 [00:01<00:00, 74.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 138/150 [00:01<00:00, 83.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:01<00:00, 77.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:08,  5.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 3/50 [00:00<00:07,  5.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5/50 [00:00<00:07,  5.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 7/50 [00:01<00:07,  5.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 9/50 [00:01<00:07,  5.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 14/50 [00:02<00:06,  5.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 16/50 [00:02<00:06,  5.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 19/50 [00:03<00:05,  5.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 21/50 [00:03<00:05,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 24/50 [00:04<00:04,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 25/50 [00:04<00:04,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 26/50 [00:04<00:05,  4.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 28/50 [00:05<00:05,  3.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 30/50 [00:05<00:05,  3.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 31/50 [00:06<00:05,  3.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 32/50 [00:06<00:05,  3.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 34/50 [00:07<00:04,  3.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 35/50 [00:07<00:04,  3.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 36/50 [00:07<00:04,  3.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 39/50 [00:08<00:02,  4.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 43/50 [00:09<00:01,  4.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 45/50 [00:09<00:01,  4.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 46/50 [00:09<00:00,  4.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 47/50 [00:10<00:00,  4.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:10<00:00,  4.67it/s]\n"
          ]
        }
      ],
      "source": [
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc_bin = DocBin()\n",
        "from spacy.util import filter_spans\n",
        "\n",
        "for text , annot in tqdm(train):\n",
        "    labels = annot['entities']\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    entity_indices = []\n",
        "    for start, end, label in labels:\n",
        "      skip_entity=False\n",
        "      for idx in range(start , end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity=True\n",
        "          break\n",
        "        if skip_entity==True:\n",
        "          continue\n",
        "        entity_indices +=list(range(start , end))\n",
        "        try:\n",
        "          span = doc.char_span(start, end, label=label, alignment_mode=\"strict\")\n",
        "        except:\n",
        "          continue\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents\n",
        "    doc_bin.add(doc)\n",
        "\n",
        "doc_bin.to_disk(\"train_1.spacy\")\n",
        "\n",
        "\n",
        "for text , annot in tqdm(test):\n",
        "    labels = annot['entities']\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    entity_indices = []\n",
        "    for start, end, label in labels:\n",
        "      skip_entity=False\n",
        "      for idx in range(start , end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity=True\n",
        "          break\n",
        "        if skip_entity==True:\n",
        "          continue\n",
        "        entity_indices +=list(range(start , end))\n",
        "        try:\n",
        "          span = doc.char_span(start, end, label=label, alignment_mode=\"strict\")\n",
        "        except:\n",
        "          continue\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents\n",
        "    doc_bin.add(doc)\n",
        "\n",
        "    doc_bin.to_disk(\"test_1.spacy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdsgnE5VAMc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck03jbqgARdJ",
        "outputId": "a2ba1367-2bdb-4e85-ef5d-c08fe1d88878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-21 05:47:06.324490: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-21 05:47:06.324552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-21 05:47:06.325866: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-21 05:47:07.638298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvQTLCGiASJP",
        "outputId": "0ed73b2d-c3e5-4828-9fb4-6091fa66c2d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-21 06:04:59.549424: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-21 06:04:59.549508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-21 06:04:59.551572: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-21 06:04:59.563773: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-21 06:05:01.528963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Created output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    697.30    0.00    0.00    0.00    0.00\n",
            "  1     200      12395.20  15542.87   37.16   38.00   36.35    0.37\n",
            "  2     400        233.84   4557.21   45.33   46.11   44.57    0.45\n",
            "  4     600       3468.19   4279.32   49.09   73.95   36.74    0.49\n",
            "  5     800       4215.60   3677.33   60.20   74.84   50.35    0.60\n",
            "  6    1000       1083.24   3142.39   66.59   71.93   61.99    0.67\n",
            "  8    1200        264.43   2639.54   60.76   78.19   49.68    0.61\n",
            "  9    1400        341.62   2513.63   66.06   83.15   54.80    0.66\n",
            " 10    1600        183.31   2240.39   70.68   72.37   69.08    0.71\n",
            " 12    1800        825.51   2158.62   71.68   69.96   73.48    0.72\n",
            " 13    2000        276.12   1997.71   72.12   79.37   66.08    0.72\n",
            " 15    2200        250.18   1685.42   74.36   82.79   67.49    0.74\n",
            " 16    2400        648.28   1618.31   74.23   75.81   72.71    0.74\n",
            " 17    2600        320.88   1574.50   73.56   87.94   63.22    0.74\n",
            " 19    2800       1840.19   1470.85   79.13   86.69   72.78    0.79\n",
            " 20    3000        354.62   1297.89   77.87   90.56   68.30    0.78\n",
            " 22    3200        347.35   1277.73   77.83   86.20   70.94    0.78\n",
            " 23    3400        458.09   1066.05   80.86   83.43   78.46    0.81\n",
            " 24    3600      12133.94   1486.05   79.79   80.82   78.77    0.80\n",
            " 26    3800        388.76   1007.79   81.85   87.30   77.05    0.82\n",
            " 27    4000       1167.67    981.63   80.36   85.67   75.67    0.80\n",
            " 29    4200        461.19    911.18   80.91   87.08   75.56    0.81\n",
            " 30    4400        558.23    905.70   82.10   88.37   76.66    0.82\n",
            " 31    4600       2103.20    933.42   79.10   78.21   80.01    0.79\n",
            " 33    4800      23036.64    972.37   81.47   85.65   77.68    0.81\n",
            " 34    5000        621.44    806.11   82.17   89.70   75.81    0.82\n",
            " 36    5200       1156.83    790.50   80.78   87.53   75.00    0.81\n",
            " 37    5400        614.49    740.43   83.47   86.70   80.47    0.83\n",
            " 39    5600       2599.27    859.06   82.46   85.76   79.41    0.82\n",
            " 40    5800        856.82    685.19   84.47   86.45   82.58    0.84\n",
            " 42    6000       1205.67    742.01   82.60   87.34   78.35    0.83\n",
            " 43    6200       1143.12    750.06   82.01   87.93   76.83    0.82\n",
            " 45    6400       2044.18    683.06   84.20   86.73   81.81    0.84\n",
            " 46    6600        991.46    618.18   84.31   88.03   80.89    0.84\n",
            " 48    6800        905.26    594.43   84.39   89.07   80.18    0.84\n",
            " 50    7000       1504.78    631.23   84.39   87.39   81.59    0.84\n",
            " 52    7200       1375.13    640.78   84.30   89.60   79.58    0.84\n",
            " 53    7400       3559.78    649.62   83.05   90.55   76.69    0.83\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train config.cfg --output ./output --paths.train ./train_1.spacy --paths.dev ./test_1.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StzUmV2UAdw-",
        "outputId": "3bff6364-204c-4ece-d66e-d449d409ddb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-21 05:47:41.604536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-21 05:47:41.604596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-21 05:47:41.605879: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-21 05:47:42.917887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.10.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxIpkY6YBK2a",
        "outputId": "28f7c56e-2757-4b20-af4f-9c09de07e767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-20 09:21:15.307577: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-20 09:21:15.307643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-20 09:21:15.309415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-20 09:21:16.686221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[1m\n",
            "============================ Data file validation ============================\u001b[0m\n",
            "\u001b[38;5;2m✔ Pipeline can be initialized with data\u001b[0m\n",
            "\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
            "\u001b[1m\n",
            "=============================== Training stats ===============================\u001b[0m\n",
            "Language: en\n",
            "Training pipeline: tok2vec, ner\n",
            "160 training docs\n",
            "160 evaluation docs\n",
            "\u001b[38;5;3m⚠ 159 training examples also in evaluation data\u001b[0m\n",
            "\u001b[38;5;3m⚠ Low number of examples to train a new pipeline (160)\u001b[0m\n",
            "\u001b[1m\n",
            "============================== Vocab & Vectors ==============================\u001b[0m\n",
            "\u001b[38;5;4mℹ 107360 total word(s) in the data (11525 unique)\u001b[0m\n",
            "\u001b[38;5;4mℹ 514157 vectors (514157 unique keys, 300 dimensions)\u001b[0m\n",
            "\u001b[38;5;3m⚠ 7620 words in training data without vectors (7%)\u001b[0m\n",
            "\u001b[1m\n",
            "========================== Named Entity Recognition ==========================\u001b[0m\n",
            "\u001b[38;5;4mℹ 11 label(s)\u001b[0m\n",
            "0 missing value(s) (tokens with '-' label)\n",
            "\u001b[38;5;1m✘ 74 invalid whitespace entity spans\u001b[0m\n",
            "\u001b[38;5;3m⚠ Low number of examples for label 'UNKNOWN' (2)\u001b[0m\n",
            "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'Years of Experience' (31)\u001b[0m\n",
            "\u001b[2K\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
            "\u001b[38;5;2m✔ No entities crossing sentence boundaries\u001b[0m\n",
            "Entity spans consisting of or starting/ending with whitespace characters are\n",
            "considered invalid.\n",
            "\u001b[1m\n",
            "================================== Summary ==================================\u001b[0m\n",
            "\u001b[38;5;2m✔ 4 checks passed\u001b[0m\n",
            "\u001b[38;5;3m⚠ 5 warnings\u001b[0m\n",
            "\u001b[38;5;1m✘ 1 error\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy debug data config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "2cXuzRSCNtP9",
        "outputId": "a8f95386-c0d5-427a-88f3-001841d53988"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pypdf2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-9c18244d5a44>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpypdf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pypdf2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import PyPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPY68_vqhXyZ"
      },
      "outputs": [],
      "source": [
        "nlp.to_disk(\"/content/mymodel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl6ZQr5bFPHy"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Uol2S3Oj-p"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('/content/output/model-best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKSlf3ocFNsD"
      },
      "outputs": [],
      "source": [
        "text=\"\"\"\n",
        "\n",
        "Relevant Coursework:\n",
        "- Machine Learning\n",
        "- Statistical Analysis\n",
        "- Data Mining\n",
        "- Big Data Analytics\n",
        "- Natural Language Processing\n",
        "- Database Management\n",
        "\n",
        "Skills:\n",
        "Programming Languages: Python, R\n",
        "Data Analysis: Pandas, NumPy, SciPy\n",
        "Machine Learning: Scikit-Learn, TensorFlow, Keras\n",
        "Statistical Analysis: RStudio, SPSS\n",
        "Data Visualization: Matplotlib, Seaborn, Tableau\n",
        "Big Data Technologies: Hadoop, Spark\n",
        "Database Management: SQL, MongoDB\n",
        "Tools: Jupyter Notebooks, Git, Docker\n",
        "Languages: Proficient in English, [Other Languages]\n",
        "\n",
        "Work Experience:\n",
        "\n",
        "Data Scientist\n",
        "[Company Name], [Location]\n",
        "[Date Started] - Present\n",
        "- Developed and implemented machine learning models for [specific purposes], resulting in a [percentage] improvement in [relevant metric].\n",
        "- Conducted exploratory data analysis (EDA) to identify trends, outliers, and patterns, contributing to improved decision-making processes.\n",
        "- Collaborated with cross-functional teams to define project goals, requirements, and deliverables.\n",
        "- Utilized big data technologies such as Hadoop and Spark to process and analyze large datasets efficiently.\n",
        "\n",
        "Data Analyst\n",
        "[Company Name], [Location]\n",
        "[Date Started] - [Date Ended]\n",
        "- Conducted statistical analysis on customer behavior data, leading to actionable insights that improved marketing strategies and increased customer retention by [percentage].\n",
        "- Created and maintained data visualizations and dashboards using Tableau for executive-level reporting.\n",
        "- Collaborated with data engineers to optimize data pipelines for efficient data extraction, transformation, and loading (ETL).\n",
        "\n",
        "Internship Experience:\n",
        "\n",
        "Data Science Intern\n",
        "[Company Name], [Location]\n",
        "[Date Started] - [Date Ended]\n",
        "- Assisted in the development and implementation of machine learning models for [specific project], contributing to a [percentage] improvement in predictive accuracy.\n",
        "- Conducted data cleaning and preprocessing tasks to ensure the quality of input data for analytical models.\n",
        "- Presented findings and recommendations to team members and stakeholders in a clear and accessible manner.\n",
        "\n",
        "Projects:\n",
        "\n",
        "1. Predictive Maintenance Model\n",
        "   - Developed a predictive maintenance model using machine learning algorithms to anticipate equipment failures, reducing downtime by [percentage].\n",
        "\n",
        "2. Sentiment Analysis of Customer Reviews\n",
        "   - Conducted sentiment analysis on customer reviews using natural language processing (NLP) techniques to provide actionable insights for product improvement.\n",
        "\n",
        "Certifications:\n",
        "\n",
        "- Certified Data Scientist (CDS), [Certification Body], [Date Earned]\n",
        "\n",
        "Professional Memberships:\n",
        "\n",
        "- Member, [Data Science Organization]\n",
        "\n",
        "References:\n",
        "\n",
        "Available upon request.\n",
        "\n",
        "Note: This template is a starting point, and you should customize it based on your unique experiences, skills, and achievements. Highlight specific projects, technical skills, and outcomes that demonstrate your proficiency as a Data Scientist. Tailor the resume to match the requirements of the positions you are applying for in the data science field.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfscRpXKFiuT"
      },
      "outputs": [],
      "source": [
        "doc=nlp('Sparsh Mahajn Senior AI engineer  delhi, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuksVueEFkdO",
        "outputId": "66425855-3056-454c-a331-a77d4079115c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsh Mahajn\n",
            "Senior AI engineer\n",
            "delhi\n",
            "indeed.com/r/Govardhana-K/ b2de315d95905b68\n",
            "6 Months\n",
            "Cloud Lending Solutions\n",
            "Oracle\n",
            "Oracle\n",
            "Cloud Lending Solutions\n",
            "Senior Consultant\n",
            "Oracle\n",
            "Staff Consultant\n",
            "Oracle\n",
            "Associate Consultant\n",
            "Oracle\n",
            "2012\n",
            "B.E in Computer Science Engineering\n",
            "Adithya Institute of Technology\n",
            "2012\n",
            "APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)\n",
            "Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x\n"
          ]
        }
      ],
      "source": [
        "for x in doc.ents:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Pd3TLQc7FmEp",
        "outputId": "8561287d-fafe-4cce-fbdf-18298b42cd22"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_807f657a-f546-49f4-aa5e-075dadec5f8a\", \"model_best_zip.zip\", 606421706)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/model_best_zip.zip')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlM8m44GHR8q",
        "outputId": "78534b2f-807c-4e63-c1cf-813309ca225d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tzip warning: name not matched: /content/output/model-best\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r /content/model_best_zip.zip . -i /content/output/model-best)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/model_best_zip.zip  /content/output/model-best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC4aFAoHJ93O"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IynX1O-wJ7QU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
